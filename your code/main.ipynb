{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Board Scraping Lab\n",
    "\n",
    "In this lab you will first see a minimal but fully functional code snippet to scrape the LinkedIn Job Search webpage. You will then work on top of the example code and complete several chanllenges.\n",
    "\n",
    "### Some Resources \n",
    "\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\"\"\"\n",
    "This function searches job posts from LinkedIn and converts the results into a dataframe.\n",
    "\"\"\"\n",
    "def scrape_linkedin_job_search(keywords):\n",
    "    \n",
    "    # Define the base url to be scraped.\n",
    "    # All uppercase variable name signifies this is a constant and its value should never unchange\n",
    "    BASE_URL = 'https://www.linkedin.com/jobs/search/?'\n",
    "    \n",
    "    # Assemble the full url with parameters\n",
    "    scrape_url = ''.join([BASE_URL, 'keywords=', keywords])\n",
    "\n",
    "    # Create a request to get the data from the server \n",
    "    page = requests.get(scrape_url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Create an empty dataframe with the columns consisting of the information you want to capture\n",
    "    columns = ['Title', 'Company', 'Location']\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Retrieve HTML code from the webpage. Parse the HTML into a list of \"cards\".\n",
    "    # Then in each job card, extract the job title, company, and location data.\n",
    "    titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    for card in soup.select(\"div.result-card__contents\"):\n",
    "        title = card.findChild(\"h3\", recursive=False)\n",
    "        company = card.findChild(\"h4\", recursive=False)\n",
    "        location = card.findChild(\"span\", attrs={\"class\": \"job-result-card__location\"}, recursive=True)\n",
    "        titles.append(title.string)\n",
    "        companies.append(company.string)\n",
    "        locations.append(location.string)\n",
    "    \n",
    "    # Inject job titles, companies, and locations into the empty dataframe\n",
    "    zipped = zip(titles, companies, locations)\n",
    "    for z in list(zipped):\n",
    "        data=data.append({'Title' : z[0] , 'Company' : z[1], 'Location': z[2]} , ignore_index=True)\n",
    "    \n",
    "    # Return dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Company, Location]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to call the function\n",
    "\n",
    "results = scrape_linkedin_job_search('data%20analysis')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#!pip install selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# Initialize the Chrome WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "# Open a web page\n",
    "driver.get(\"https://www.linkedin.com\")\n",
    "\n",
    "jobs_button = driver.find_elements(by='xpath', value='//a[@data-tracking-control-name=\"guest_homepage-basic_guest_nav_menu_jobs\"]')[0]\n",
    "jobs_button.click()\n",
    "time.sleep(1)\n",
    "\n",
    "sign_in_button = driver.find_elements(by='xpath', value='//button[@data-tracking-control-name=\"public_jobs_contextual-sign-in-modal_modal_dismiss\"]')[0]\n",
    "sign_in_button.click()\n",
    "time.sleep(1)\n",
    "\n",
    "country_input = driver.find_elements(by='xpath', value='//input[@id=\"job-search-bar-location\"]')[0]\n",
    "time.sleep(1)\n",
    "country_input.clear()\n",
    "country_input.send_keys(\"germany\")\n",
    "time.sleep(1)\n",
    "\n",
    "job_input = driver.find_elements(by='xpath', value='//input[@data-tracking-control-name=\"public_jobs_dismissable-input\"]')[0]\n",
    "job_input.send_keys(\"python\")\n",
    "time.sleep(1)\n",
    "job_list = driver.find_elements(by='xpath', value='//li[@id=\"keywords-1\"]')[0]\n",
    "job_list.click()\n",
    "\n",
    "count = 0\n",
    "while (not driver.find_elements(by='xpath', value='//button[@data-tracking-control-name=\"infinite-scroller_show-more\"]')) or count<=10:\n",
    "    print(count)\n",
    "    count += 1\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "\n",
    "job_posts = driver.find_elements(by='xpath', value='//a[@data-tracking-control-name=\"public_jobs_jserp-result_search-card\"]')\n",
    "time.sleep(1)\n",
    "\n",
    "job_names = []\n",
    "#company_names = []\n",
    "job_links = []\n",
    "\n",
    "for job_post in job_posts:\n",
    "    if job_post.get_attribute('href'):\n",
    "        job_links.append(job_post.get_attribute('href'))\n",
    "    else:\n",
    "        job_links.append(None)\n",
    "\n",
    "    if job_post.find_element(by='xpath', value='.//span'):\n",
    "        job_names.append(job_post.find_element(by='xpath', value='.//span').text)\n",
    "    else:\n",
    "        job_names.append(None)\n",
    "\n",
    "    #if job_post.find_element(by='xpath', value='.//h4'):\n",
    "    #    company_names.append(job_post.find_element(by='xpath', value='.//h4').text)\n",
    "    #else:\n",
    "    #    company_names.append(None)\n",
    "    \n",
    "time.sleep(2)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Software Engineer</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/senior-pytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI Engineer (Intern)</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/ai-engineer-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Internship - Software Development</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/internship-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineer III, Core Development, Python</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/software-eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/software-dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2025-2026 AI/ML Research Fellow</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/2025-2026-ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Strategy Analyst</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/strategy-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Junior Software Engineer</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/junior-softw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Graduate Software Engineer</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/graduate-sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>https://de.linkedin.com/jobs/view/ai-engineer-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Title  \\\n",
       "0                   Senior Python Software Engineer   \n",
       "1                              AI Engineer (Intern)   \n",
       "2                 Internship - Software Development   \n",
       "3   Software Engineer III, Core Development, Python   \n",
       "4                                Software Developer   \n",
       "..                                              ...   \n",
       "75                  2025-2026 AI/ML Research Fellow   \n",
       "76                                 Strategy Analyst   \n",
       "77                         Junior Software Engineer   \n",
       "78                       Graduate Software Engineer   \n",
       "79                                      AI Engineer   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://de.linkedin.com/jobs/view/senior-pytho...  \n",
       "1   https://de.linkedin.com/jobs/view/ai-engineer-...  \n",
       "2   https://de.linkedin.com/jobs/view/internship-s...  \n",
       "3   https://de.linkedin.com/jobs/view/software-eng...  \n",
       "4   https://de.linkedin.com/jobs/view/software-dev...  \n",
       "..                                                ...  \n",
       "75  https://de.linkedin.com/jobs/view/2025-2026-ai...  \n",
       "76  https://de.linkedin.com/jobs/view/strategy-ana...  \n",
       "77  https://de.linkedin.com/jobs/view/junior-softw...  \n",
       "78  https://de.linkedin.com/jobs/view/graduate-sof...  \n",
       "79  https://de.linkedin.com/jobs/view/ai-engineer-...  \n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\"Job Title\": job_names, \"Link\": job_links})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "The first challenge for you is to update the `scrape_linkedin_job_search` function by adding a new parameter called `num_pages`. This will allow you to search more than 25 jobs with this function. Suggested steps:\n",
    "\n",
    "1. Go to https://www.linkedin.com/jobs/search/?keywords=data%20analysis in your browser.\n",
    "1. Scroll down the left panel and click the page 2 link. Look at how the URL changes and identify the page offset parameter.\n",
    "1. Add `num_pages` as a new param to the `scrape_linkedin_job_search` function. Update the function code so that it uses a \"for\" loop to retrieve several pages of search results.\n",
    "1. Test your new function by scraping 5 pages of the search results.\n",
    "\n",
    "Hint: Prepare for the case where there are less than 5 pages of search results. Your function should be robust enough to **not** trigger errors. Simply skip making additional searches and return all results if the search already reaches the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#!pip install selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scrape_linkedin_job_search_2():\n",
    "\n",
    "    # Initialize the Chrome WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    # Open a web page\n",
    "    driver.get(\"https://www.linkedin.com\")\n",
    "\n",
    "    jobs_button = driver.find_elements(by='xpath', value='//a[@data-tracking-control-name=\"guest_homepage-basic_guest_nav_menu_jobs\"]')[0]\n",
    "    jobs_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    sign_in_button = driver.find_elements(by='xpath', value='//button[@data-tracking-control-name=\"public_jobs_contextual-sign-in-modal_modal_dismiss\"]')[0]\n",
    "    sign_in_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    country_input = driver.find_elements(by='xpath', value='//input[@id=\"job-search-bar-location\"]')[0]\n",
    "    time.sleep(1)\n",
    "    country_input.clear()\n",
    "    country_input.send_keys(\"germany\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    job_input = driver.find_elements(by='xpath', value='//input[@data-tracking-control-name=\"public_jobs_dismissable-input\"]')[0]\n",
    "    job_input.send_keys(\"python\")\n",
    "    time.sleep(1)\n",
    "    job_list = driver.find_elements(by='xpath', value='//li[@id=\"keywords-1\"]')[0]\n",
    "    job_list.click()\n",
    "\n",
    "    count = 0\n",
    "    # while loop to search for more than the initial set of jobs\n",
    "    while (not driver.find_elements(by='xpath', value='//button[@data-tracking-control-name=\"infinite-scroller_show-more\"]')) or count<=10:\n",
    "        \n",
    "        count += 1\n",
    "        # upward scroll is necessary so linked in allows the next lazyload batch\n",
    "        driver.execute_script(\"window.scrollBy(0, -300);\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    job_posts = driver.find_elements(by='xpath', value='//a[@data-tracking-control-name=\"public_jobs_jserp-result_search-card\"]')\n",
    "    time.sleep(1)\n",
    "\n",
    "    job_names = []\n",
    "    #company_names = []\n",
    "    job_links = []\n",
    "\n",
    "    for job_post in job_posts:\n",
    "        if job_post.get_attribute('href'):\n",
    "            job_links.append(job_post.get_attribute('href'))\n",
    "        else:\n",
    "            job_links.append(None)\n",
    "\n",
    "        if job_post.find_element(by='xpath', value='.//span'):\n",
    "            job_names.append(job_post.find_element(by='xpath', value='.//span').text)\n",
    "        else:\n",
    "            job_names.append(None)\n",
    "\n",
    "        #if job_post.find_element(by='xpath', value='.//h4'):\n",
    "        #    company_names.append(job_post.find_element(by='xpath', value='.//h4').text)\n",
    "        #else:\n",
    "        #    company_names.append(None)\n",
    "        \n",
    "    time.sleep(2)\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame({\"Job Title\": job_names, \"Link\": job_links})\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "                                            Job Title  \\\n",
      "0                     Senior Python Software Engineer   \n",
      "1                                AI Engineer (Intern)   \n",
      "2                   Internship - Software Development   \n",
      "3     Software Engineer III, Core Development, Python   \n",
      "4                                  Software Developer   \n",
      "..                                                ...   \n",
      "95                              AI Specialist (m/f/d)   \n",
      "96  Backend Developer (m/w/d) – PHP / Web Applicat...   \n",
      "97  Deutsche Bank Graduate Programme (f/m/x) in Be...   \n",
      "98                       AI Platform Engineer (m/f/d)   \n",
      "99  Python Developer for Desktop Applications (m/f/d)   \n",
      "\n",
      "                                                 Link  \n",
      "0   https://de.linkedin.com/jobs/view/senior-pytho...  \n",
      "1   https://de.linkedin.com/jobs/view/ai-engineer-...  \n",
      "2   https://de.linkedin.com/jobs/view/internship-s...  \n",
      "3   https://de.linkedin.com/jobs/view/software-eng...  \n",
      "4   https://de.linkedin.com/jobs/view/software-dev...  \n",
      "..                                                ...  \n",
      "95  https://de.linkedin.com/jobs/view/ai-specialis...  \n",
      "96  https://de.linkedin.com/jobs/view/backend-deve...  \n",
      "97  https://de.linkedin.com/jobs/view/deutsche-ban...  \n",
      "98  https://de.linkedin.com/jobs/view/ai-platform-...  \n",
      "99  https://de.linkedin.com/jobs/view/python-devel...  \n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = scrape_linkedin_job_search_2()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "Further improve your function so that it can search jobs in a specific country. Add the 3rd param to your function called `country`. The steps are identical to those in Challange 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scrape_linkedin_job_search_3(country):\n",
    "\n",
    "    # Initialize the Chrome WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    # Open a web page\n",
    "    driver.get(\"https://www.linkedin.com\")\n",
    "\n",
    "    jobs_button = driver.find_elements(by='xpath', value='//a[@data-tracking-control-name=\"guest_homepage-basic_guest_nav_menu_jobs\"]')[0]\n",
    "    jobs_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    sign_in_button = driver.find_elements(by='xpath', value='//button[@data-tracking-control-name=\"public_jobs_contextual-sign-in-modal_modal_dismiss\"]')[0]\n",
    "    sign_in_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    country_input = driver.find_elements(by='xpath', value='//input[@id=\"job-search-bar-location\"]')[0]\n",
    "    time.sleep(1)\n",
    "    country_input.clear()\n",
    "    country_input.send_keys(country)\n",
    "    time.sleep(1)\n",
    "\n",
    "    job_input = driver.find_elements(by='xpath', value='//input[@data-tracking-control-name=\"public_jobs_dismissable-input\"]')[0]\n",
    "    job_input.send_keys(\"python\")\n",
    "    time.sleep(1)\n",
    "    job_list = driver.find_elements(by='xpath', value='//li[@id=\"keywords-1\"]')[0]\n",
    "    job_list.click()\n",
    "\n",
    "    count = 0\n",
    "    # while loop to search for more than the initial set of jobs\n",
    "    while (not driver.find_elements(by='xpath', value='//button[@data-tracking-control-name=\"infinite-scroller_show-more\"]')) or count<=10:\n",
    "        \n",
    "        count += 1\n",
    "        # upward scroll is necessary so linked in allows the next lazyload batch\n",
    "        driver.execute_script(\"window.scrollBy(0, -300);\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    job_posts = driver.find_elements(by='xpath', value='//a[@data-tracking-control-name=\"public_jobs_jserp-result_search-card\"]')\n",
    "    time.sleep(1)\n",
    "\n",
    "    job_names = []\n",
    "    #company_names = []\n",
    "    job_links = []\n",
    "\n",
    "    for job_post in job_posts:\n",
    "        if job_post.get_attribute('href'):\n",
    "            job_links.append(job_post.get_attribute('href'))\n",
    "        else:\n",
    "            job_links.append(None)\n",
    "\n",
    "        if job_post.find_element(by='xpath', value='.//span'):\n",
    "            job_names.append(job_post.find_element(by='xpath', value='.//span').text)\n",
    "        else:\n",
    "            job_names.append(None)\n",
    "\n",
    "        #if job_post.find_element(by='xpath', value='.//h4'):\n",
    "        #    company_names.append(job_post.find_element(by='xpath', value='.//h4').text)\n",
    "        #else:\n",
    "        #    company_names.append(None)\n",
    "        \n",
    "    time.sleep(2)\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame({\"Job Title\": job_names, \"Link\": job_links})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Job Title  \\\n",
      "0                     Junior Software Engineer   \n",
      "1   Graduate Software Engineer 2025 - Platform   \n",
      "2           Backend Software Engineer (Python)   \n",
      "3                    Machine Learning Engineer   \n",
      "4    Graduate Software Engineer 2025 - RegTech   \n",
      "..                                         ...   \n",
      "85                            Python Developer   \n",
      "86                              Data Scientist   \n",
      "87                  Graduate Software Engineer   \n",
      "88                            Python Developer   \n",
      "89                                 AI Engineer   \n",
      "\n",
      "                                                 Link  \n",
      "0   https://uk.linkedin.com/jobs/view/junior-softw...  \n",
      "1   https://uk.linkedin.com/jobs/view/graduate-sof...  \n",
      "2   https://uk.linkedin.com/jobs/view/backend-soft...  \n",
      "3   https://uk.linkedin.com/jobs/view/machine-lear...  \n",
      "4   https://uk.linkedin.com/jobs/view/graduate-sof...  \n",
      "..                                                ...  \n",
      "85  https://uk.linkedin.com/jobs/view/python-devel...  \n",
      "86  https://uk.linkedin.com/jobs/view/data-scienti...  \n",
      "87  https://uk.linkedin.com/jobs/view/graduate-sof...  \n",
      "88  https://uk.linkedin.com/jobs/view/python-devel...  \n",
      "89  https://uk.linkedin.com/jobs/view/ai-engineer-...  \n",
      "\n",
      "[90 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = scrape_linkedin_job_search_3(\"England\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "Add the 4th param called `num_days` to your function to allow it to search jobs posted in the past X days. Note that in the LinkedIn job search the searched timespan is specified with the following param:\n",
    "\n",
    "```\n",
    "f_TPR=r259200\n",
    "```\n",
    "\n",
    "The number part in the param value is the number of seconds. 259,200 seconds equal to 3 days. You need to convert `num_days` to number of seconds and supply that info to LinkedIn job search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scrape_linkedin_job_search_4(country, num_days):\n",
    "    \n",
    "    linkedin_timeparameter = 60*60*24*num_days\n",
    "   \n",
    "    # Initialize the Chrome WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    # Open a web page\n",
    "    driver.get(\"https://www.linkedin.com\")\n",
    "\n",
    "    # navigate to jobs\n",
    "    jobs_button = driver.find_elements(by='xpath', value='//a[@data-tracking-control-name=\"guest_homepage-basic_guest_nav_menu_jobs\"]')[0]\n",
    "    jobs_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Click X button of sign In pop up\n",
    "    sign_in_button = driver.find_elements(by='xpath', value='//button[@data-tracking-control-name=\"public_jobs_contextual-sign-in-modal_modal_dismiss\"]')[0]\n",
    "    sign_in_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    \n",
    "\n",
    "    # enter Country\n",
    "    country_input = driver.find_elements(by='xpath', value='//input[@id=\"job-search-bar-location\"]')[0]\n",
    "    time.sleep(1)\n",
    "    country_input.clear()\n",
    "    country_input.send_keys(country)\n",
    "    time.sleep(1)\n",
    "\n",
    "    job_input = driver.find_elements(by='xpath', value='//input[@data-tracking-control-name=\"public_jobs_dismissable-input\"]')[0]\n",
    "    job_input.send_keys(\"python\")\n",
    "    time.sleep(1)\n",
    "    job_list = driver.find_elements(by='xpath', value='//li[@id=\"keywords-1\"]')[0]\n",
    "    job_list.click()\n",
    "\n",
    "    # change Timespan in URL\n",
    "    current_url = driver.current_url\n",
    "    new_url = current_url + \"&f_TPR=r\" + str(linkedin_timeparameter)\n",
    "    driver.get(new_url)\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    # while loop to search for more than the initial set of jobs\n",
    "    while (not driver.find_elements(by='xpath', value='//button[@data-tracking-control-name=\"infinite-scroller_show-more\"]')) or count<=10:\n",
    "        \n",
    "        count += 1\n",
    "        # upward scroll is necessary so linked in allows the next lazyload batch\n",
    "        driver.execute_script(\"window.scrollBy(0, -300);\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    job_posts = driver.find_elements(by='xpath', value='//a[@data-tracking-control-name=\"public_jobs_jserp-result_search-card\"]')\n",
    "    time.sleep(1)\n",
    "\n",
    "    job_names = []\n",
    "    #company_names = []\n",
    "    job_links = []\n",
    "\n",
    "    for job_post in job_posts:\n",
    "        if job_post.get_attribute('href'):\n",
    "            job_links.append(job_post.get_attribute('href'))\n",
    "        else:\n",
    "            job_links.append(None)\n",
    "\n",
    "        if job_post.find_element(by='xpath', value='.//span'):\n",
    "            job_names.append(job_post.find_element(by='xpath', value='.//span').text)\n",
    "        else:\n",
    "            job_names.append(None)\n",
    "\n",
    "        #if job_post.find_element(by='xpath', value='.//h4'):\n",
    "        #    company_names.append(job_post.find_element(by='xpath', value='.//h4').text)\n",
    "        #else:\n",
    "        #    company_names.append(None)\n",
    "        \n",
    "    time.sleep(2)\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame({\"Job Title\": job_names, \"Link\": job_links})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Job Title  \\\n",
      "0                                  Software Developer   \n",
      "1                  Backend Software Engineer (Python)   \n",
      "2                Data Scientist (all genders welcome)   \n",
      "3                    Research Scientist | Language AI   \n",
      "4   Graduate Software Developer - STEM / Physics /...   \n",
      "..                                                ...   \n",
      "95                              SRE / DevOps Engineer   \n",
      "96  DevOps Engineer (Software-Oriented) - Luxembou...   \n",
      "97  Postdoctoral researcher modeling and assessing...   \n",
      "98                   (Senior) DevOps Engineer (f/m/d)   \n",
      "99  IBM Z Software Entwickler (m/w/x) für Systems ...   \n",
      "\n",
      "                                                 Link  \n",
      "0   https://de.linkedin.com/jobs/view/software-dev...  \n",
      "1   https://de.linkedin.com/jobs/view/backend-soft...  \n",
      "2   https://de.linkedin.com/jobs/view/data-scienti...  \n",
      "3   https://de.linkedin.com/jobs/view/research-sci...  \n",
      "4   https://de.linkedin.com/jobs/view/graduate-sof...  \n",
      "..                                                ...  \n",
      "95  https://de.linkedin.com/jobs/view/sre-devops-e...  \n",
      "96  https://de.linkedin.com/jobs/view/devops-engin...  \n",
      "97  https://de.linkedin.com/jobs/view/postdoctoral...  \n",
      "98  https://de.linkedin.com/jobs/view/senior-devop...  \n",
      "99  https://de.linkedin.com/jobs/view/ibm-z-softwa...  \n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = scrape_linkedin_job_search_4(\"Germany\", 5)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Allow your function to also retrieve the \"Seniority Level\" of each job searched. Note that the Seniority Level info is not in the initial search results. You need to make a separate search request for each job card based on the `currentJobId` value which you can extract from the job card HTML.\n",
    "\n",
    "After you obtain the Seniority Level info, update the function and add it to a new column of the returned dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
